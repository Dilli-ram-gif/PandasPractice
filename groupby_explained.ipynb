{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3b7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  22000   30days    1000.0\n",
      "1  PySpark  25000   50days    2300.0\n",
      "2   Hadoop  23000   55days    1000.0\n",
      "3   Python  24000   40days    1200.0\n",
      "4   Pandas  26000   60days    2500.0\n",
      "5   Hadoop  25000   35days       NaN\n",
      "6    Spark  25000   30days    1400.0\n",
      "7   Python  22000   50days    1600.0\n",
      "8       NA   1500   40days       0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\",\"NA\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000,1500],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','30days','50days','40days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,None,1400,1600,0]\n",
    "          })\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b4421bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Marks  Rank\n",
      "Courses             \n",
      "English    175     9\n",
      "Math       155     5\n",
      "Science    185     7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use groupby() to compute the sum\n",
    "df2 =df.groupby('Courses').sum()\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ad5e37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses  Marks\n",
      "0  English    175\n",
      "1     Math    155\n",
      "2  Science    185\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Courses': ['Math', 'Science', 'English', 'Math', 'Science', 'English'],\n",
    "    'Marks': [80, 90, 85, 75, 95, 90],\n",
    "    'Rank': [1, 2, 3, 4, 5, 6]\n",
    "})\n",
    "\n",
    "# Group data by course and sum marks\n",
    "df_grouped = df.groupby('Courses')['Marks'].sum().reset_index()\n",
    "\n",
    "print(df_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb6feab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Science</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Courses  Marks\n",
       "0  English    175\n",
       "1     Math    155\n",
       "2  Science    185"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0164fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  22000   30days    1000.0\n",
      "1  PySpark  25000   50days    2300.0\n",
      "2   Hadoop  23000   55days    1000.0\n",
      "3   Python  24000   40days    1200.0\n",
      "4   Pandas  26000   60days    2500.0\n",
      "5   Hadoop  25000   35days       NaN\n",
      "6    Spark  25000   30days    1400.0\n",
      "7   Python  22000   50days    1600.0\n",
      "8       NA   1500   40days       0.0\n",
      "           Fee  Discount\n",
      "Courses                 \n",
      "Hadoop   48000    1000.0\n",
      "NA        1500       0.0\n",
      "Pandas   26000    2500.0\n",
      "PySpark  25000    2300.0\n",
      "Python   46000    2800.0\n",
      "Spark    47000    2400.0\n",
      "                    Fee  Discount\n",
      "Courses Duration                 \n",
      "Hadoop  35days    25000       0.0\n",
      "        55days    23000    1000.0\n",
      "NA      40days     1500       0.0\n",
      "Pandas  60days    26000    2500.0\n",
      "PySpark 50days    25000    2300.0\n",
      "Python  40days    24000    1200.0\n",
      "        50days    22000    1600.0\n",
      "Spark   30days    47000    2400.0\n",
      "   Courses Duration    Fee  Discount\n",
      "0   Hadoop   35days  25000       0.0\n",
      "1   Hadoop   55days  23000    1000.0\n",
      "2       NA   40days   1500       0.0\n",
      "3   Pandas   60days  26000    2500.0\n",
      "4  PySpark   50days  25000    2300.0\n",
      "5   Python   40days  24000    1200.0\n",
      "6   Python   50days  22000    1600.0\n",
      "7    Spark   30days  47000    2400.0\n",
      "   Courses    Fee\n",
      "0   Hadoop  48000\n",
      "1       NA   1500\n",
      "2   Pandas  26000\n",
      "3  PySpark  25000\n",
      "4   Python  46000\n",
      "5    Spark  47000\n",
      "           Fee  Discount\n",
      "Courses                 \n",
      "Spark    47000    2400.0\n",
      "PySpark  25000    2300.0\n",
      "Hadoop   48000    1000.0\n",
      "Python   46000    2800.0\n",
      "Pandas   26000    2500.0\n",
      "NA        1500       0.0\n",
      "           Fee  Discount\n",
      "Courses                 \n",
      "Spark    47000    2400.0\n",
      "Python   46000    2800.0\n",
      "PySpark  25000    2300.0\n",
      "Pandas   26000    2500.0\n",
      "NA        1500       0.0\n",
      "Hadoop   48000    1000.0\n",
      "           min    max\n",
      "Courses              \n",
      "Hadoop   23000  25000\n",
      "NA        1500   1500\n",
      "Pandas   26000  26000\n",
      "PySpark  25000  25000\n",
      "Python   22000  24000\n",
      "Spark    22000  25000\n",
      "        Duration    Fee       \n",
      "           count    min    max\n",
      "Courses                       \n",
      "Hadoop         2  23000  25000\n",
      "NA             1   1500   1500\n",
      "Pandas         1  26000  26000\n",
      "PySpark        1  25000  25000\n",
      "Python         2  22000  24000\n",
      "Spark          2  22000  25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_15124\\155433084.py:12: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df2 =df.groupby(['Courses']).sum()\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_15124\\155433084.py:28: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df2=df.groupby(by=['Courses'], sort=False).sum()\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_15124\\155433084.py:32: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  groupedDF = df.groupby('Courses',sort=False).sum()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\",\"NA\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000,1500],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','30days','50days','40days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,None,1400,1600,0]\n",
    "          })\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)\n",
    "\n",
    "# Use groupby() to compute the sum\n",
    "df2 =df.groupby(['Courses']).sum()\n",
    "print(df2)\n",
    "\n",
    "# Group by on multiple columns\n",
    "df2 =df.groupby(['Courses', 'Duration']).sum()\n",
    "print(df2)\n",
    "\n",
    "# Set Index on group by results\n",
    "df2 = df.groupby(['Courses','Duration']).sum().reset_index()\n",
    "print(df2)\n",
    "\n",
    "# Using groupby on single column in pandas \n",
    "df2 = df.groupby(['Courses'])['Fee'].sum().reset_index()\n",
    "print(df2)\n",
    "\n",
    "# Ignore sorting on group by key\n",
    "df2=df.groupby(by=['Courses'], sort=False).sum()\n",
    "print(df2)\n",
    "\n",
    "# Sort group key on descending order\n",
    "groupedDF = df.groupby('Courses',sort=False).sum()\n",
    "sortedDF=groupedDF.sort_values('Courses', ascending=False)\n",
    "print(sortedDF)\n",
    "\n",
    "# Groupby & multiple aggregations\n",
    "result = df.groupby('Courses')['Fee'].aggregate(['min','max'])\n",
    "print(result)\n",
    "\n",
    "# Groupby multiple columns & multiple aggregations\n",
    "result = df.groupby('Courses').aggregate({'Duration':'count','Fee':['min','max']})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a68689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
